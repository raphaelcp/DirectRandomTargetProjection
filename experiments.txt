Experimento 1 - arquitetura de melhor resultado do paper para o dataset MNIST

python main.py --dataset MNIST --train-mode DRTP --optimizer NAG --freeze-conv-layers --trials 10 --batch-size 60 --epochs 100 --lr 0.0015 --dropout 0.1 --topology FC_1000_FC_10 --hidden-act tanh --output-act sigmoid

Experimento 2

python main.py --dataset MNIST --train-mode DRTP --optimizer Adam  --trials 5 --batch-size 200 --epochs 200 --lr 0.00005 --topology   --hidden-act tanh --output-act sigmoid


    parser.add_argument('--topology', type=str, default='CONV_32_5_1_2_FC_1000_FC_10', help='Choice of network topology. Format for convolutional layers: CONV_{output channels}_{kernel size}_{stride}_{padding}. Format for fully-connected layers: FC_{output units}.'

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++=====+++++++++

python main.py --dataset MNIST --train-mode DRTP --optimizer Adam  --trials 1 --batch-size 200 --epochs 200 --lr 0.00005 --topology CONV_64_3_1_1_CONV_64_3_1_1_CONV_128_3_1_1_CONV_128_3_1_1_CONV_256_3_1_1_CONV_256_3_1_1_CONV_256_3_1_1_CONV_512_3_1_1_CONV_512_3_1_1_CONVP_512_3_1_1_CONV_512_3_1_1_CONV_512_3_1_1_CONVP_512_3_1_1_FC_512_FC_512_FC_10 --hidden-act relu --output-act softmax

python main.py --dataset CIFAR10aug --train-mode DFA --optimizer Adam  --trials 1 --batch-size 200 --epochs 200 --lr 0.00005 --topology CONV_64_3_1_1_CONV_64_3_1_1_CONV_128_3_1_1_CONV_128_3_1_1_CONV_256_3_1_1_CONV_256_3_1_1_CONV_256_3_1_1_CONV_512_3_1_1_CONV_512_3_1_1_CONVP_512_3_1_1_CONV_512_3_1_1_CONV_512_3_1_1_CONVP_512_3_1_1_FC_512_FC_512_FC_10 --hidden-act relu --output-act softmax

	python main.py --dataset MNIST --train-mode BP --optimizer Adam  --trials 1 --batch-size 200 --epochs 200 --lr 0.00005 --topology CONV_512_3_1_1_CONV_512_3_1_1_CONVP_512_3_1_1_CONV_512_3_1_1_CONV_512_3_1_1_CONVP_512_3_1_1_FC_512_FC_256_FC_10 --hidden-act relu --output-act softmax


=== Model ===
NetworkBuilder(
  (layers): ModuleList(
    (0): CNN_block(
      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): Activation(
        (act): Tanh()
      )
      (hook): TrainingHook (BP)
    )
    (1): CNN_block(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): Activation(
        (act): Tanh()
      )
      (hook): TrainingHook (BP)
    )
    (2): CNN_block(
      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): Activation(
        (act): Tanh()
      )
      (hook): TrainingHook (BP)
    )
    (3): CNN_block(
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): Activation(
        (act): Tanh()
      )
      (hook): TrainingHook (BP)
    )
    (4): CNN_block(
      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): Activation(
        (act): Tanh()
      )
      (hook): TrainingHook (BP)
    )
    (5): CNN_block(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): Activation(
        (act): Tanh()
      )
      (hook): TrainingHook (BP)
    )
    (6): CNN_block(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): Activation(
        (act): Tanh()
      )
      (hook): TrainingHook (BP)
    )
    (7): CNN_block(
      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): Activation(
        (act): Tanh()
      )
      (hook): TrainingHook (BP)
    )
    (8): CNN_block(
      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): Activation(
        (act): Tanh()
      )
      (hook): TrainingHook (BP)
    )
    (9): CNNP_block(
      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): Activation(
        (act): Tanh()
      )
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (hook): TrainingHook (BP)
    )
    (10): CNN_block(
      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): Activation(
        (act): Tanh()
      )
      (hook): TrainingHook (BP)
    )
    (11): CNN_block(
      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): Activation(
        (act): Tanh()
      )
      (hook): TrainingHook (BP)
    )
    (12): CNNP_block(
      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (act): Activation(
        (act): Tanh()
      )
      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (hook): TrainingHook (BP)
    )
    (13): FC_block(
      (fc): Linear(in_features=131072, out_features=512, bias=True)
      (act): Activation(
        (act): ReLU()
      )
      (hook): TrainingHook (BP)
    )
    (14): FC_block(
      (fc): Linear(in_features=512, out_features=512, bias=True)
      (act): Activation(
        (act): ReLU()
      )
      (hook): TrainingHook (BP)
    )
    (15): FC_block(
      (fc): Linear(in_features=512, out_features=10, bias=True)
      (act): Activation(
        (act): Softmax(dim=None)
      )
      (hook): TrainingHook (BP)
    )
  )
)


